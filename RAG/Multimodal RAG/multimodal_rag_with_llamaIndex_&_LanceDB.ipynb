{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MultiModal RAG App for Video Processing With LlamaIndex and LanceDB\n",
        "1. llamaindex framework\n",
        "2. Lancedb Vector DataBase\n",
        "3. LLM MultiModAl GPT-4V or Google-gemini-pro-vision"
      ],
      "metadata": {
        "id": "1w8W4CSx3dOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps Need to follow:\n",
        "1. Download video from YouTube, process and store it.\n",
        "\n",
        "2. Build Multi-Modal index and vector store for both texts and images.\n",
        "\n",
        "3. Retrieve relevant images and context, use both to augment the prompt.\n",
        "\n",
        "4. Using GPT4V for reasoning the correlations between the input query and augmented data and generating final response.**"
      ],
      "metadata": {
        "id": "WW-xaGr24B_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama-index-vector-stores-lancedb\n",
        "%pip install llama-index-multi-modal-llms-openai\n",
        "%pip install llama-index-embeddings-clip\n",
        "%pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install llama-index-readers-file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6E4GruH4oYT",
        "outputId": "51b2bbc0-f841-4da4-d1a2-ce4f4e961bc3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index-vector-stores-lancedb in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
            "Requirement already satisfied: lancedb>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-lancedb) (0.24.2)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-lancedb) (0.13.2)\n",
            "Requirement already satisfied: pylance in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-lancedb) (0.33.0)\n",
            "Requirement already satisfied: tantivy in /usr/local/lib/python3.11/dist-packages (from llama-index-vector-stores-lancedb) (0.24.0)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (2.0.2)\n",
            "Requirement already satisfied: overrides>=0.7 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (7.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (25.0)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (18.1.0)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (2.11.7)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from lancedb>=0.21.1->llama-index-vector-stores-lancedb) (4.67.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.9.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (4.3.8)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb>=0.21.1->llama-index-vector-stores-lancedb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb>=0.21.1->llama-index-vector-stores-lancedb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb>=0.21.1->llama-index-vector-stores-lancedb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-vector-stores-lancedb) (3.0.2)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-multi-modal-llms-openai) (0.13.2)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-multi-modal-llms-openai) (0.5.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.17.2)\n",
            "Requirement already satisfied: openai<2,>=1.81.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-openai<0.6,>=0.5.0->llama-index-multi-modal-llms-openai) (1.99.8)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2024.11.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-multi-modal-llms-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-multi-modal-llms-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-multi-modal-llms-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2,>=1.81.0->llama-index-llms-openai<0.6,>=0.5.0->llama-index-multi-modal-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.26.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (25.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-multi-modal-llms-openai) (3.0.2)\n",
            "Collecting llama-index-embeddings-clip\n",
            "  Downloading llama_index_embeddings_clip-0.5.0-py3-none-any.whl.metadata (365 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-clip) (0.13.2)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.17.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-embeddings-clip) (3.0.2)\n",
            "Downloading llama_index_embeddings_clip-0.5.0-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: llama-index-embeddings-clip\n",
            "Successfully installed llama-index-embeddings-clip-0.5.0\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-68ethna5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-68ethna5\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Using cached ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (25.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->clip==1.0)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Using cached ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369549 sha256=271e277c6e836b0a0a8f5549952ae45f690ff6f4d274be0cc7ab6ce54532f58b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k8sw64pl/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting llama-index-readers-file\n",
            "  Downloading llama_index_readers_file-0.5.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (0.7.1)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (0.13.2)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file) (2.2.2)\n",
            "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file)\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file) (4.14.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.5)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (4.67.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.17.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.1.6)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2024.11.6)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.26.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.16.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (25.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index-readers-file) (3.0.2)\n",
            "Downloading llama_index_readers_file-0.5.1-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, pypdf, llama-index-readers-file\n",
            "Successfully installed llama-index-readers-file-0.5.1 pypdf-5.9.0 striprtf-0.0.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install llama_index\n",
        "%pip install -U openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubKjBpZe52NY",
        "outputId": "43786920-2624-42fe-93ae-90317046f2d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama_index)\n",
            "  Downloading llama_index_cli-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.13.2)\n",
            "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama_index)\n",
            "  Downloading llama_index_embeddings_openai-0.5.0-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama_index) (0.5.1)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama_index) (3.9.1)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (2025.3.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (1.3.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (2.0.2)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (11.3.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (2.11.7)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.2->llama_index) (2.0.43)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (0.11.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (4.14.1)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.2->llama_index) (1.17.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.99.8)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama_index) (2025.8.3)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (5.9.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama_index) (0.0.26)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.14,>=0.13.2->llama_index) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.2->llama_index) (1.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.2->llama_index) (3.1.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.2->llama_index) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.2->llama_index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.2->llama_index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.2->llama_index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.2->llama_index) (0.4.0)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama_index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.2->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.2->llama_index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.2->llama_index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.2->llama_index) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->llama-index-core<0.14,>=0.13.2->llama_index) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.2->llama_index) (3.2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.2->llama_index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.2->llama_index) (3.26.1)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv<2,>=1.0.1 (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama_index)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.14,>=0.13.2->llama_index) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama_index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.2->llama_index) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.2->llama_index) (3.0.2)\n",
            "Downloading llama_index-0.13.2-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_cli-0.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_embeddings_openai-0.5.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.9.1-py3-none-any.whl (16 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.0-py3-none-any.whl (3.2 kB)\n",
            "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, llama-cloud, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-cli, llama-index-readers-llama-parse, llama_index\n",
            "Successfully installed llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-cli-0.5.0 llama-index-embeddings-openai-0.5.0 llama-index-indices-managed-llama-cloud-0.9.1 llama-index-readers-llama-parse-0.5.0 llama-parse-0.6.54 llama_index-0.13.2 python-dotenv-1.1.1\n",
            "Collecting openai-whisper\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=2d671fc35d24bfcc60accaa6c81029d7477794e597f3517de224e1c465e992df\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/d2/9a/801b5cc5b2a1af2e280089b71c326711a682fc1d50ea29d0ed\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: openai-whisper\n",
            "Successfully installed openai-whisper-20250625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%pip install lancedb\n",
        "%pip install moviepy\n",
        "%pip install pytube\n",
        "%pip install pydub\n",
        "%pip install SpeechRecognition\n",
        "%pip install ffmpeg-python\n",
        "%pip install soundfile\n",
        "%pip install torch torchvision\n",
        "%pip install matplotlib scikit-image\n",
        "%pip install ftfy regex tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ6Wvzoa52XN",
        "outputId": "c31644fc-c79f-4910-a216-e012c217b0ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lancedb in /usr/local/lib/python3.11/dist-packages (0.24.2)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.11/dist-packages (from lancedb) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lancedb) (2.0.2)\n",
            "Requirement already satisfied: overrides>=0.7 in /usr/local/lib/python3.11/dist-packages (from lancedb) (7.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lancedb) (25.0)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.11/dist-packages (from lancedb) (18.1.0)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.11/dist-packages (from lancedb) (2.11.7)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from lancedb) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10->lancedb) (0.4.1)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.8.3)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.1)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ffmpeg**-library enables you to use FFmpeg in Python to manipulate various media files for different purposes like building comprehensive multimedia applications, preprocessing media files.\n",
        "\n",
        "**MoviePy** is a Python library for video editing, enabling cutting, concatenations, title insertions, video compositing, and effects like animations or color grading.\n",
        "\n",
        "**Pytube** is a Python library used for downloading videos from YouTube. It supports downloading in various formats, resolutions, and also direct audio extraction.\n",
        "\n",
        "**Pydub** is a Python library for audio manipulation, enabling easy loading, editing, and exporting of audio files in various formats with minimal code.\n",
        "\n",
        "The **SpeechRecognition** library in Python allows you to convert spoken language into text using various engines and APIs, such as Google Speech Recognition, IBM Speech to Text, etc.\n",
        "\n",
        "**SoundFile** is a Python library for reading from and writing to audio files, supporting many formats through the libsndfile library, ideal for high-quality audio processing.\n",
        "\n",
        "**FTFY** (Fix Text For You) is a Python library that fixes broken Unicode text and mojibake (garbled text due to encoding issues), making text legible again.\n",
        "\n",
        "**OpenAI Whisper** is a robust, multilingual speech recognition model developed by OpenAI. It converts speech into text and supports various languages with high accuracy.\n",
        "\n",
        "**pprint** is a Python module that provides a capability to \"pretty-print\" complex data structures in a well-formatted and more readable way than the basic print function."
      ],
      "metadata": {
        "id": "uWNwvygB68-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "from pathlib import Path\n",
        "import speech_recognition as sr\n",
        "from pytube import YouTube\n",
        "from pprint import pprint\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TUD52r1v7eX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "OPENAI_API_TOKEN=userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN"
      ],
      "metadata": {
        "id": "tFfCYDsy7p_H"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1FeMee870Do",
        "outputId": "686de9cd-01d7-4bf3-cdc2-ac0bc5ef8ee7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_url=\"https://youtu.be/yIYKR4sgzI8?si=gXmg-aTIhioj1pOs\""
      ],
      "metadata": {
        "id": "NSzDIEiQ7_P7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_video_path = \"/content/video_data/\""
      ],
      "metadata": {
        "id": "0KwBi8aS8g2r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from the video we'll collect images,audio,text\n",
        "output_folder = \"/content/mixed_data/\"\n",
        "output_audio_path = \"/content/mixed_data/output_audio.wav\""
      ],
      "metadata": {
        "id": "I0xiTzw_8mAM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir mixed_data"
      ],
      "metadata": {
        "id": "Zmy_QJyB81I8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = output_video_path + \"input_vid.mp4\"\n",
        "print(filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT1cDFvB81Lw",
        "outputId": "a7e421f9-5e20-458c-a95c-0de194413ed3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/video_data/input_vid.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 1. The problem with **pytube**\n",
        "\n",
        "* **Pytube** is a Python library that allows you to download YouTube videos, playlists, captions, etc.\n",
        "* However, it **frequently breaks** because:\n",
        "\n",
        "  * YouTube constantly updates its frontend JavaScript and API structure.\n",
        "  * Pytube relies on parsing YouTube’s web pages and JavaScript to extract the **stream URLs** and metadata.\n",
        "  * Even a small change in YouTube’s HTML/JS (e.g., renaming variables, changing request signatures) can cause errors like:\n",
        "\n",
        "    * `RegexMatchError`\n",
        "    * `VideoUnavailable`\n",
        "    * `KeyError: 'cipher'`\n",
        "  * Pytube maintainers are often slow to push fixes, so the library can stay broken for weeks.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. What **pytubefix** does\n",
        "\n",
        "* **pytubefix** is a **community-maintained fork** of pytube.\n",
        "* Its main goal is to keep up with **YouTube’s frequent changes** more quickly.\n",
        "* It fixes broken regex parsing and API issues whenever YouTube updates.\n",
        "\n",
        "Key points:\n",
        "\n",
        "* **Actively maintained** with patches for YouTube site changes.\n",
        "* Supports **video download, audio extraction, playlists, captions** just like pytube.\n",
        "* Handles **deciphering video stream URLs** (the “ciphered signatures” issue that breaks pytube often).\n",
        "* Often provides more **accurate video metadata and stats** (views, title, length, publish date, description, etc.) because its parsing scripts are updated.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Example: Video Stats Issue\n",
        "\n",
        "In pytube:\n",
        "\n",
        "```python\n",
        "from pytube import YouTube\n",
        "\n",
        "yt = YouTube(\"https://www.youtube.com/watch?v=abc123\")\n",
        "print(yt.views)   # might fail or give wrong result if regex broke\n",
        "```\n",
        "\n",
        "If YouTube updated their JS, you might get:\n",
        "\n",
        "* Wrong views count\n",
        "* Errors like `RegexMatchError`\n",
        "\n",
        "In pytubefix:\n",
        "\n",
        "```python\n",
        "from pytubefix import YouTube\n",
        "\n",
        "yt = YouTube(\"https://www.youtube.com/watch?v=abc123\")\n",
        "print(yt.views)   # works, because fix updated regex\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "✅ **In short:**\n",
        "\n",
        "* **pytube breaks often** because YouTube changes its frontend.\n",
        "* **pytubefix** is a fork that patches those issues quickly, making downloads and video stats retrieval work reliably.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rmjl99XLkpQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytubefix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_TTSdOfum0m",
        "outputId": "30ad3350-540b-44d9-ee27-03e56db34801"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytubefix\n",
            "  Downloading pytubefix-9.4.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: aiohttp>=3.12.13 in /usr/local/lib/python3.11/dist-packages (from pytubefix) (3.12.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.12.13->pytubefix) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.12.13->pytubefix) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp>=3.12.13->pytubefix) (3.10)\n",
            "Downloading pytubefix-9.4.1-py3-none-any.whl (768 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/768.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m768.0/768.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m768.6/768.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytubefix\n",
            "Successfully installed pytubefix-9.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytubefix import YouTube\n",
        "def download_video(url,output_path):\n",
        "  video_id = url.split('?')[0].split('/')[-1]\n",
        "  watch_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "\n",
        "  yt = YouTube(watch_url)  #   from pytubefix, not pytube\n",
        "  metadata = {\"Author\": yt.author, \"Title\": yt.title, \"Views\": yt.views}\n",
        "\n",
        "  yt.streams.get_highest_resolution().download(\n",
        "        output_path=output_path, filename=\"input_vid.mp4\"\n",
        "    )\n",
        "  return metadata"
      ],
      "metadata": {
        "id": "bwXP3IEa81Ov"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "def video_to_images(video_path,output_folder):\n",
        "  clip=VideoFileClip(video_path)\n",
        "  clip.write_images_sequence(\n",
        "      os.path.join(output_folder,\"frame%04d.png\"),fps=0.2\n",
        "  )"
      ],
      "metadata": {
        "id": "GCZsIZFM81SJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_to_audio(video_path,output_audio_path):\n",
        "  clip=VideoFileClip(video_path)\n",
        "  audio=clip.audio\n",
        "  audio.write_audiofile(output_audio_path)"
      ],
      "metadata": {
        "id": "11_nZ0UeAINw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def audio_to_text(audio_path):\n",
        "  recognizer=sr.Recognizer()\n",
        "  audio=sr.AudioFile(audio_path)\n",
        "\n",
        "  with audio as source:\n",
        "    audio_data=recognizer.record(source)\n",
        "\n",
        "    try:\n",
        "\n",
        "      #recognize the speech\n",
        "      text = recognizer.recognize_whisper(audio_data)\n",
        "\n",
        "    except sr.UnknownValueError:\n",
        "      print(\"Speech recognition could not understand the audio.\")\n",
        "  return text"
      ],
      "metadata": {
        "id": "Uo2-WZISAIQu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yrWisHw7FceU",
        "outputId": "d53cab6c-0176-4780-bb2e-18711748a17f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://youtu.be/yIYKR4sgzI8?si=gXmg-aTIhioj1pOs'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_video_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Fnz4nlbEFcm7",
        "outputId": "8c8974c6-ec8f-4b83-86c9-666cba1bfae9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/video_data/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=download_video(video_url,output_video_path)\n",
        "metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiM1wpV2PCCX",
        "outputId": "a5352329-3c5c-48bb-f058-ace4c5687dfc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Author': 'StatQuest with Josh Starmer',\n",
              " 'Title': 'StatQuest: Logistic Regression',\n",
              " 'Views': 2504050}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_to_images(filepath,output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RruuULSFkmfq",
        "outputId": "e437b4c7-2b22-44f8-a642-410d3911fb95"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Writing frames /content/mixed_data/frame%04d.png.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                              "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done writing frames /content/mixed_data/frame%04d.png.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RpGmPg_nkmi5",
        "outputId": "2291755b-9646-40e6-bac3-79b873aec084"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/video_data/input_vid.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_audio_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s5Xd4rKfkmmS",
        "outputId": "af05258b-e84b-47df-f2fd-566bf24ab8c3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mixed_data/output_audio.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_to_audio(filepath,output_audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAIfwEmakmpW",
        "outputId": "c9fc4e24-a207-4e79-fe97-f96f1cbbbb2d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/mixed_data/output_audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data=audio_to_text(output_audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHYhKN23kmse",
        "outputId": "f430e380-21cf-43bc-faa5-3b104c79898d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 121MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "dWr56Um3kmvV",
        "outputId": "332972c2-d183-4b3e-adf7-f775e78ba9ee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" If you can fit a line, you can fit a squiggle. If you can make me laugh, you can make me giggle. StatQuest. Hello, I'm Josh Starmer and welcome to StatQuest. Today we're going to talk about logistic regression. This is a technique that can be used for traditional statistics as well as machine learning. So let's get right to it. Before we dive into logistic regression, let's take a step back and review linear regression. In another StatQuest, we talked about linear regression. We had some data, weight and size. Then we fit a line to it. And with that line, we could do a lot of things. First, we could calculate R squared and determine if weight and size are correlated. Large values imply a large effect. And second, calculate a p-value to determine if the R squared value is statistically significant. And third, we could use the line to predict size given weight. If a new mouse has this weight, then this is the size that we predict from the weight. Although we didn't mention it at the time, using data to predict something falls under the category of machine learning. So plain old linear regression is a form of machine learning. We also talked a little bit about multiple regression. Now we are trying to predict size using weight and blood volume. Alternatively, we could say that we are trying to model size using weight and blood volume. Multiple regression did the same things that normal regression did. We calculated R squared and we calculated the p-value. And we could predict size using weight and blood volume. And this makes multiple regression a slightly fancier machine learning method. We also talked about how we can use discrete measurements like genotype to predict size. If you're not familiar with the term genotype, don't freak out. It's no big deal. Just know that it refers to different types of mice. Lastly, we could compare models. So on the left side, we've got normal regression using weight to predict size. And we can compare those predictions to the ones we get from multiple regression, where we're using weight and blood volume to predict size. Comparing the simple model to the complicated one tells us if we need to measure weight and blood volume to accurately predict size. Or if we can get away with just weight. Now that we remember all the cool things we can do with linear regression, let's talk about logistic regression. Logistic regression is similar to linear regression except logistic regression predicts whether something is true or false instead of predicting something continuous like size. These mice are obese and these mice are not. Also, instead of fitting a line to the data, logistic regression fits an S-shaped logistic function. The curve goes from 0 to 1. And that means that the curve tells you the probability that a mouse is obese based on its weight. If we weighed a very heavy mouse, there is a high probability that the new mouse is obese. If we weighed an intermediate mouse, then there is only a 50% chance that the mouse is obese. Lastly, there's only a small probability that a light mouse is obese. Although logistic regression tells the probability that a mouse is obese or not, it's usually used for classification. For example, if the probability a mouse is obese is greater than 50%, then we'll classify it as obese. Otherwise, we'll classify it as not obese. Just like with linear regression, we can make simple models. In this case, we can have obesity predicted by weight or more complicated models. In this case, obesity is predicted by weight and genotype. In this case, obesity is predicted by weight and genotype and age. And lastly, obesity is predicted by weight, genotype, age, and astrological sign. In other words, just like linear regression, logistic regression can work with continuous data like weight and age and discrete data like genotype and astrological sign. We can also test to see if each variable is useful for predicting obesity. However, unlike normal regression, we can't easily compare the complicated model to the simple model and we'll talk more about why in a bit. Instead, we just test to see if a variable's effect on the prediction is significantly different from zero. If not, it means that the variable is not helping the prediction. Psst, we use Wald's test to figure this out. We'll talk about that in another stack quest. In this case, the astrological sign is totes useless. That's statistical jargon for not helping. That means we can save time and space in our study by leaving it out. Logistic regression's ability to provide probabilities and classify new samples using continuous and discrete measurements makes it a popular machine learning method. One big difference between linear regression and logistic regression is how the line is fit to the data. With linear regression, we fit the line using least squares. In other words, we find the line that minimizes the sum of the squares of these residuals. We also use the residuals to calculate R squared and to compare simple models to complicated models. Logistic regression doesn't have the same concept of a residual, so it can't use least squares and it can't calculate R squared. Instead, it uses something called maximum likelihood. There's a whole stack quest on maximum likelihood, so see that for details, but in a nutshell, you pick a probability scaled by weight of observing an obese mouse just like this curve. And you use that to calculate the likelihood of observing a non-obese mouse that weighs this much. And then you calculate the likelihood of observing this mouse. And you do that for all of the mice. And lastly, you multiply all of those likelihoods together. That's the likelihood of the data given this line. Then you shift the line and calculate a new likelihood of the data. And then shift the line and calculate the likelihood again. And again. Finally, the curve with the maximum value for the likelihood is selected. Bam! In summary, logistic regression can be used to classify samples. And it can use different types of data, like size and or genotype, to do that classification. And it can also be used to assess what variables are useful for classifying samples. i.e. Astrological Sign is Toats useless. Hooray! We've made it to the end of another exciting stack quest. If you like this stack quest and want to see more, please subscribe. And if you have suggestions for future stack quests, well, put them in the comments below. Until next time, Quest On!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " If you can fit a line, you can fit a squiggle. If you can make me laugh, you can make me giggle. StatQuest. Hello, I'm Josh Starmer and welcome to StatQuest. Today we're going to talk about logistic regression. This is a technique that can be used for traditional statistics as well as machine learning. So let's get right to it. Before we dive into logistic regression, let's take a step back and review linear regression. In another StatQuest, we talked about linear regression. We had some data, weight and size. Then we fit a line to it. And with that line, we could do a lot of things. First, we could calculate R squared and determine if weight and size are correlated. Large values imply a large effect. And second, calculate a p-value to determine if the R squared value is statistically significant. And third, we could use the line to predict size given weight. If a new mouse has this weight, then this is the size that we predict from the weight. Although we didn't mention it at the time, using data to predict something falls under the category of machine learning. So plain old linear regression is a form of machine learning. We also talked a little bit about multiple regression. Now we are trying to predict size using weight and blood volume. Alternatively, we could say that we are trying to model size using weight and blood volume. Multiple regression did the same things that normal regression did. We calculated R squared and we calculated the p-value. And we could predict size using weight and blood volume. And this makes multiple regression a slightly fancier machine learning method. We also talked about how we can use discrete measurements like genotype to predict size. If you're not familiar with the term genotype, don't freak out. It's no big deal. Just know that it refers to different types of mice. Lastly, we could compare models. So on the left side, we've got normal regression using weight to predict size. And we can compare those predictions to the ones we get from multiple regression where we're using weight and blood volume to predict size. Comparing the simple model to the complicated one tells us if we need to measure weight and blood volume to accurately predict size. Or if we can get away with just weight. Now that we remember all the cool things we can do with linear regression, let's talk about logistic regression. Logistic regression is similar to linear regression except logistic regression predicts whether something is true or false instead of predicting something continuous like size. These mice are obese and these mice are not. Also, instead of fitting a line to the data, logistic regression fits an S-shaped logistic function. The curve goes from 0 to 1. And that means that the curve tells you the probability that a mouse is obese based on its weight. If we weighed a very heavy mouse, there's a high probability that the new mouse is obese. If we weighed an intermediate mouse, then there's only a 50% chance that the mouse is obese. Lastly, there's only a small probability that a light mouse is obese. Although logistic regression tells the probability that a mouse is obese or not, it's usually used for classification. For example, if the probability a mouse is obese is greater than 50%, then we'll classify it as obese. Otherwise, we'll classify it as not obese. Just like with linear regression, we can make simple models. In this case, we can have obesity predicted by weight, or more complicated models. In this case, obesity is predicted by weight and genotype. In this case, obesity is predicted by weight and genotype and age. And lastly, obesity is predicted by weight, genotype, age, and astrological sign. In other words, just like linear regression, logistic regression can work with continuous data, like weight and age, and discrete data, like genotype and astrological sign. We can also test to see if each variable is useful for predicting obesity. However, unlike normal regression, we can't easily compare the complicated model to the simple model, and we'll talk more about why in a bit. Instead, we just test to see if a variable's effect on the prediction is significantly different from zero. If not, it means that the variable is not helping the prediction. Psst! We use Wald's test to figure this out. We'll talk about that in another stack quest. In this case, the astrological sign is totes useless. That's statistical jargon for not helping. That means we can save time and space in our study by leaving it out. Logistic regressions' ability to provide probabilities and classify new samples using continuous and discrete measurements makes it a popular machine learning method. One big difference between linear regression and logistic regression is how the line is fit to the data. With linear regression, we fit the line using least squares. In other words, we find the line that minimizes the sum of the squares of these residuals. We also use the residuals to calculate R squared and to compare simple models to complicated models. Logistic regression doesn't have the same concept of a residual, so it can't use least squares and it can't calculate R squared. Instead, it uses something called maximum likelihood. There's a whole stack quest on maximum likelihood, so see that for details, but in a nutshell, you pick a probability scaled by weight of observing an obese mouse, just like this curve. And you use that to calculate the likelihood of observing a non-obese mouse that weighs this much. And then you calculate the likelihood of observing this mouse. And you do that for all of the mice. And lastly, you multiply all of those likelihoods together. That's the likelihood of the data given this line. Then you shift the line and calculate a new likelihood of the data. And then shift the line and calculate the likelihood again. And again. Finally, the curve with the maximum value for the likelihood is selected. Bam! In summary, logistic regression can be used to classify samples. And it can use different types of data, like size and or genotype, to do that classification. And it can also be used to assess what variables are useful for classifying samples. I.e. astrological sign is totes useless. Hooray! We've made it to the end of another exciting stack quest. If you like this stack quest and want to see more, please subscribe. Many feedback suggestions for future stack quests. Well, put them in the comments below. Until next time, quest on!"
      ],
      "metadata": {
        "id": "fqbcfOXpkmyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(output_folder + \"output_text.txt\", \"w\") as file:\n",
        "        file.write(text_data)\n",
        "print(\"Text data saved to file\")\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QrURMq4km1W",
        "outputId": "8eb67666-3bc9-4e4d-d3e7-cedbdf5f2371"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text data saved to file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.remove(output_audio_path)\n",
        "# print(\"Audio file removed\")  # Optional process since we have already generated text data from audio file so we use that text data and convert it into embeddings ......"
      ],
      "metadata": {
        "id": "QDJKomjMkm4S"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processing the video......\n",
        "# images , text data"
      ],
      "metadata": {
        "id": "URYArdwQsZ5N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "go through this ---https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/indices/multi_modal/base.py to  know more about class MultiModalVectorStoreIndex"
      ],
      "metadata": {
        "id": "jc2BgeYhtuio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlamaIndex Core Classes Explained\n",
        "\n",
        "### **MultiModalVectorStoreIndex**\n",
        "\n",
        "The **MultiModalVectorStoreIndex** is a specialized index class in LlamaIndex designed to handle multi-modal data - specifically text and images. This class extends the functionality of the standard VectorStoreIndex to support multiple data modalities within a single indexing structure.[1][2]\n",
        "\n",
        "**Key Features:**\n",
        "- **Multi-Modal Support**: Can process both text documents and images simultaneously[1]\n",
        "- **Separate Vector Stores**: Maintains distinct vector stores for text and image embeddings, allowing for optimized storage and retrieval of different data types[1]\n",
        "- **Flexible Embedding Models**: Supports arbitrary text embedding models (default is GPT-3.5) and image embedding models (default is CLIP)[1]\n",
        "- **Retrieval Capabilities**: Enables text-to-text, text-to-image, and image-to-image retrieval operations[1]\n",
        "\n",
        "**Usage Example:**\n",
        "```python\n",
        "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
        "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "\n",
        "# Create separate vector stores for text and images\n",
        "text_store = QdrantVectorStore(client=client, collection_name=\"text_collection\")\n",
        "image_store = QdrantVectorStore(client=client, collection_name=\"image_collection\")\n",
        "\n",
        "# Set up storage context with both stores\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=text_store,\n",
        "    image_store=image_store\n",
        ")\n",
        "\n",
        "# Load documents (can include both text and images)\n",
        "documents = SimpleDirectoryReader(\"./data_folder/\").load_data()\n",
        "\n",
        "# Create the multi-modal index\n",
        "index = MultiModalVectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context\n",
        ")\n",
        "```\n",
        "\n",
        "**Class Properties:**\n",
        "- Inherits from `VectorStoreIndex`\n",
        "- Has an `image_namespace` property set to \"image\"\n",
        "- Uses `MultiModelIndexDict` as its index structure[2]\n",
        "\n",
        "### **SimpleDirectoryReader**\n",
        "\n",
        "The **SimpleDirectoryReader** is LlamaIndex's primary data loading utility that automatically reads and processes various file types from directories. It serves as the entry point for ingesting documents into LlamaIndex workflows.[3]\n",
        "\n",
        "**Core Functionality:**\n",
        "- **Automatic File Detection**: Automatically detects and processes supported file formats including PDF, DOCX, TXT, CSV, and many others[3]\n",
        "- **Recursive Directory Reading**: Can traverse subdirectories when `recursive=True` is set[3]\n",
        "- **Parallel Processing**: Supports multi-worker processing for faster file loading[3]\n",
        "- **Metadata Extraction**: Automatically extracts file metadata such as file path, name, type, size, and timestamps[4]\n",
        "\n",
        "**Key Parameters:**\n",
        "- `input_dir`: The directory path to read files from\n",
        "- `input_files`: Specific list of files to load (alternative to directory scanning)\n",
        "- `recursive`: Whether to read files from subdirectories\n",
        "- `file_extractor`: Custom mapping of file extensions to reader classes\n",
        "- `exclude`: List of files to exclude from loading\n",
        "- `num_workers`: Number of parallel workers for processing[3]\n",
        "\n",
        "**Usage Examples:**\n",
        "```python\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# Basic usage - load all supported files from directory\n",
        "reader = SimpleDirectoryReader(input_dir=\"path/to/directory\")\n",
        "documents = reader.load_data()\n",
        "\n",
        "# Load with parallel processing\n",
        "documents = reader.load_data(num_workers=4)\n",
        "\n",
        "# Load recursively from subdirectories\n",
        "reader = SimpleDirectoryReader(input_dir=\"path/to/directory\", recursive=True)\n",
        "documents = reader.load_data()\n",
        "\n",
        "# Iterate over files as they load\n",
        "for docs in reader.iter_data():\n",
        "    # Process documents per file\n",
        "    all_docs.extend(docs)\n",
        "```\n",
        "\n",
        "**Document Structure:**\n",
        "Each document returned by `load_data()` contains:[4]\n",
        "- `text`: The extracted content from the file\n",
        "- `metadata`: Dictionary with file information (file_path, file_name, file_type, etc.)\n",
        "- `id_`: Optional document identifier (can be set to filename with `filename_as_id=True`)\n",
        "\n",
        "**Extensibility:**\n",
        "The reader can be extended to support custom file types by providing a `file_extractor` dictionary mapping file extensions to custom `BaseReader` implementations.[3]\n",
        "\n",
        "### **StorageContext**\n",
        "\n",
        "The **StorageContext** is LlamaIndex's central storage management class that provides a unified interface for handling different storage backends. It acts as a container that coordinates between document storage, index storage, and vector storage.[5][6]\n",
        "\n",
        "**Core Components:**\n",
        "The StorageContext manages three main storage types:[6][5]\n",
        "- **Document Store (docstore)**: Stores the actual document nodes and their content\n",
        "- **Index Store (index_store)**: Stores index metadata and structural information\n",
        "- **Vector Store (vector_store)**: Stores embedding vectors for similarity search\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "**`from_defaults()` Class Method:**\n",
        "Creates a StorageContext with default configurations, allowing customization of individual components:[5][6]\n",
        "```python\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "# Create with all defaults\n",
        "storage_context = StorageContext.from_defaults()\n",
        "\n",
        "# Create with custom vector store\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    vector_store=custom_vector_store,\n",
        "    persist_dir=\"./my_storage\"\n",
        ")\n",
        "\n",
        "# Create with custom components\n",
        "storage_context = StorageContext.from_defaults(\n",
        "    docstore=custom_docstore,\n",
        "    index_store=custom_index_store,\n",
        "    vector_store=custom_vector_store\n",
        ")\n",
        "```\n",
        "\n",
        "**`persist()` Method:**\n",
        "Saves all storage components to disk:[5]\n",
        "```python\n",
        "# Persist to default location (./storage)\n",
        "storage_context.persist()\n",
        "\n",
        "# Persist to custom directory\n",
        "storage_context.persist(persist_dir=\"./my_custom_storage\")\n",
        "```\n",
        "\n",
        "**`add_vector_store()` Method:**\n",
        "Allows adding additional vector stores with custom namespaces for multi-modal or specialized use cases.[5]\n",
        "\n",
        "**Storage Backends:**\n",
        "StorageContext supports various storage backends through different store implementations:[7]\n",
        "- **Local Filesystem**: Default option for development and small-scale applications\n",
        "- **MongoDB**: For distributed document and index storage\n",
        "- **Redis**: For high-performance caching and storage\n",
        "- **Cloud Storage**: AWS S3, Azure, Google Cloud through fsspec integration\n",
        "\n",
        "**Persistence and Loading:**\n",
        "```python\n",
        "# Save index and context\n",
        "index.storage_context.persist(persist_dir=\"./storage\")\n",
        "\n",
        "# Load from saved state\n",
        "from llama_index.core import load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "index = load_index_from_storage(storage_context)\n",
        "```\n",
        "\n",
        "**Integration with Indexes:**\n",
        "StorageContext is typically used when creating indexes to specify where and how data should be stored:\n",
        "```python\n",
        "# Use with VectorStoreIndex\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context\n",
        ")\n",
        "\n",
        "# Use with MultiModalVectorStoreIndex\n",
        "index = MultiModalVectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context=storage_context\n",
        ")\n",
        "```\n",
        "\n",
        "The StorageContext provides flexibility in data persistence, allowing developers to choose appropriate storage backends based on their application's scale, performance requirements, and infrastructure constraints.[8][9]\n",
        "\n",
        "[1] https://docs.llamaindex.ai/en/stable/module_guides/models/multi_modal/\n",
        "[2] https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/indices/multi_modal/base.py\n",
        "[3] https://docs.llamaindex.ai/en/stable/module_guides/loading/simpledirectoryreader/\n",
        "[4] https://github.com/run-llama/llama_index/discussions/11970\n",
        "[5] https://docs.llamaindex.ai/en/stable/api_reference/storage/storage_context/\n",
        "[6] https://docs.llamaindex.ai/en/v0.10.18/api_reference/storage.html\n",
        "[7] https://github.com/run-llama/llama_index/blob/main/docs/docs/module_guides/storing/index_stores.md\n",
        "[8] https://nanonets.com/blog/llamaindex/\n",
        "[9] https://www.gettingstarted.ai/llamaindex-storage-customization-persisting-and-loading-data/\n",
        "[10] https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/\n",
        "[11] https://github.com/run-llama/llama_index/issues/13102\n",
        "[12] https://pypi.org/project/llama-index/\n",
        "[13] https://llama-index.readthedocs.io/zh/stable/reference/storage.html\n",
        "[14] https://stackoverflow.com/questions/77984729/importerror-cannot-import-name-vectorstoreindex-from-llama-index-unknown-l\n",
        "[15] https://docs.llmhub.t-systems.net/Model%20Serving/llama-index\n",
        "[16] https://docs.llamaindex.ai/en/v0.10.19/api_reference/storage.html\n",
        "[17] https://docs.llamaindex.ai/en/stable/understanding/storing/storing/\n",
        "[18] https://qdrant.tech/documentation/frameworks/llama-index/\n",
        "[19] https://docs.llamaindex.ai/en/v0.9.48/api/llama_index.readers.SimpleDirectoryReader.html\n",
        "[20] https://wentao.site/llama_index_2/\n",
        "[21] https://stackoverflow.com/questions/78125440/loading-data-with-llama-index-after-upgrading-package-cant-find-readers-file\n",
        "[22] https://docs.pinecone.io/integrations/llamaindex\n",
        "[23] https://stackoverflow.com/questions/76832028/importerror-cannot-import-name-simpledirectoryreader-from-llama-index-unkn\n",
        "[24] https://github.com/run-llama/llama_index/issues/10621\n",
        "[25] https://huggingface.co/llamaindex\n",
        "[26] https://stackoverflow.com/questions/76837143/llamaindex-index-storage-context-persist-not-storing-vector-store\n",
        "[27] https://llamaindexxx.readthedocs.io/en/latest/api_reference/storage.html\n",
        "[28] https://www.youtube.com/watch?v=Cu5KQz3c4Zk\n",
        "[29] https://github.com/run-llama/llama_index/issues/2499\n",
        "[30] https://github.com/run-llama/llama_index/issues/12571\n",
        "[31] https://llama-index.readthedocs.io/zh/stable/how_to/storage/save_load.html\n",
        "[32] https://github.com/run-llama/llama_index"
      ],
      "metadata": {
        "id": "oR19rsXwuKlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import StorageContext"
      ],
      "metadata": {
        "id": "c01uK4Tikm7v"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore"
      ],
      "metadata": {
        "id": "DffdhyKisFj8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_store=LanceDBVectorStore(uri=\"lancedb\",table_name=\"text_collection\")\n",
        "image_store=LanceDBVectorStore(uri=\"lancedb\",table_name=\"image_collection\")"
      ],
      "metadata": {
        "id": "RQ9pY3FrsFm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_context=StorageContext.from_defaults(vector_store=text_store,image_store=image_store)"
      ],
      "metadata": {
        "id": "ZCIQvW4VsFqL"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OFCNWlB8sFs1",
        "outputId": "366eaec6-ceae-4a2a-de6b-5cba9dc0849a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/mixed_data/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents=SimpleDirectoryReader(output_folder).load_data()"
      ],
      "metadata": {
        "id": "3Ap0JFjlsFvy"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = MultiModalVectorStoreIndex.from_documents(documents,storage_context=storage_context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOQVJLTysFyn",
        "outputId": "12b03de1-a587-4622-c5ce-6b2da1a9fbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.embeddings.openai.utils:Retrying llama_index.embeddings.openai.base.OpenAIEmbedding._get_text_embeddings.<locals>._retryable_get_embeddings in 1.0 seconds as it raised RateLimitError: Error code: 429 - {'error': {'message': 'Your account is not active, please check your billing details on our website.', 'type': 'billing_not_active', 'param': None, 'code': 'billing_not_active'}}.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_engine=index.as_retriever(similarity_top_k=3, image_similarity_top_k=10)"
      ],
      "metadata": {
        "id": "doGcY9Y9sF1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_tmpl_str=(\n",
        "    \"Based on the provided information, including relevant images and retrieved context from the video, \\\n",
        "    accurately and precisely answer the query without any additional prior knowledge.\\n\"\n",
        "\n",
        "    \"---------------------\\n\"\n",
        "    \"Metadata for video: {metadata_str} \\n\"\n",
        "\n",
        "    \"---------------------\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"Answer: \"\n",
        ")"
      ],
      "metadata": {
        "id": "ogvnW0UNwweO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.notebook_utils import display_source_node\n",
        "from llama_index.core.schema import ImageNode"
      ],
      "metadata": {
        "id": "XTX4iLS8sF4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(retriever_engine, query_str):\n",
        "    retrieval_results = retriever_engine.retrieve(query_str)\n",
        "\n",
        "    retrieved_image = []\n",
        "    retrieved_text = []\n",
        "    for res_node in retrieval_results:\n",
        "        if isinstance(res_node.node, ImageNode):\n",
        "            retrieved_image.append(res_node.node.metadata[\"file_path\"])\n",
        "        else:\n",
        "            display_source_node(res_node, source_length=200)\n",
        "            retrieved_text.append(res_node.text)\n",
        "\n",
        "    return retrieved_image, retrieved_text"
      ],
      "metadata": {
        "id": "punkDkYgv7tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"Tell me about logistic regression? Explain equations of logistic regression?\""
      ],
      "metadata": {
        "id": "Fdv_jFp5v7w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,text=retrieve(retriever_engine,query)"
      ],
      "metadata": {
        "id": "kGHNJJZBv70i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_images(images_path):\n",
        "  images_shown = 0\n",
        "  plt.figure(figsize=(16, 9))\n",
        "  for img_path in images_path:\n",
        "        if os.path.isfile(img_path):\n",
        "            image = Image.open(img_path)\n",
        "\n",
        "            plt.subplot(2, 3, images_shown + 1)\n",
        "            plt.imshow(image)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "\n",
        "            images_shown += 1\n",
        "            if images_shown >= 5:\n",
        "                break"
      ],
      "metadata": {
        "id": "47OeMwz5v8DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "CulOLyaVzebj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(img)"
      ],
      "metadata": {
        "id": "lHSUgE-_v8Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JtKvKuJDv8bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YRE-E2q-zqfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWhUPMnR18Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_tmpl_str=(\n",
        "    \"Based on the provided information, including relevant images and retrieved context from the video, \\\n",
        "    accurately and precisely answer the query without any additional prior knowledge.\\n\"\n",
        "\n",
        "    \"---------------------\\n\"\n",
        "    \"Context: {context_str}\\n\"\n",
        "    \"Metadata for video: {metadata_str} \\n\"\n",
        "\n",
        "    \"---------------------\\n\"\n",
        "    \"Query: {query_str}\\n\"\n",
        "    \"Answer: \"\n",
        ")"
      ],
      "metadata": {
        "id": "MezwZ3Wc18J4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "metadata_str=json.dumps(metadata)"
      ],
      "metadata": {
        "id": "2Ddwb2uQzqi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.multi_modal_llms.openai import OpenAIMultiModal"
      ],
      "metadata": {
        "id": "I5NJDEFOyvNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_mm_llm = OpenAIMultiModal(model=\"gpt-4-vision-preview\", api_key=OPENAI_API_TOKEN, max_new_tokens=1500)"
      ],
      "metadata": {
        "id": "cR-1KVvTyvRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_str =\"Tell me about logistic regression? Explain equations of logistic regression?\""
      ],
      "metadata": {
        "id": "Lgjl-OVBzMUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_str = \"\".join(text)"
      ],
      "metadata": {
        "id": "8PdjqtHqzmjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_documents = SimpleDirectoryReader( input_files=img).load_data()"
      ],
      "metadata": {
        "id": "HXQ5pAnAzMYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=openai_mm_llm.complete(\n",
        "    prompt=qa_tmpl_str.format(\n",
        "        query_str=query_str,metadata_str=metadata_str\n",
        "    ),\n",
        "    image_documents=image_documents,\n",
        ")"
      ],
      "metadata": {
        "id": "6Z1TbwNFyvUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(result.text)"
      ],
      "metadata": {
        "id": "WCJ_Xys6sF8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VzEUx1ibsGEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install yt-dlp\n",
        "# !pip install ffmpeg-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3NOLq3BJ8D7",
        "outputId": "d1a6f7ee-39b1-4726-8619-59d3faa34c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.7.21)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import yt_dlp\n",
        "# import os\n",
        "# import json\n",
        "# from pathlib import Path\n",
        "\n",
        "# def download_video_with_ytdlp(url, output_path):\n",
        "#     \"\"\"\n",
        "#     Download video using yt-dlp with comprehensive metadata extraction\n",
        "#     \"\"\"\n",
        "#     # Create output directory\n",
        "#     os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "#     # Configure yt-dlp options\n",
        "#     ydl_opts = {\n",
        "#         'format': 'best[ext=mp4][height<=720]/best[ext=mp4]/best',  # Prefer mp4, max 720p for efficiency\n",
        "#         'outtmpl': os.path.join(output_path, 'input_vid.%(ext)s'),\n",
        "#         'writeinfojson': True,  # Save metadata to JSON file\n",
        "#         'writethumbnail': True,  # Download thumbnail\n",
        "#         'writesubtitles': False,  # Set to True if you want subtitles\n",
        "#         'writeautomaticsub': False,  # Set to True for auto-generated subtitles\n",
        "#     }\n",
        "\n",
        "#     try:\n",
        "#         print(f\"🎥 Starting download from: {url}\")\n",
        "\n",
        "#         with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "#             # Extract info first\n",
        "#             info = ydl.extract_info(url, download=False)\n",
        "\n",
        "#             # Print basic info\n",
        "#             print(f\"📹 Title: {info.get('title', 'Unknown')}\")\n",
        "#             print(f\"👤 Author: {info.get('uploader', 'Unknown')}\")\n",
        "#             print(f\"⏱️ Duration: {info.get('duration', 0)} seconds\")\n",
        "#             print(f\"👀 Views: {info.get('view_count', 0):,}\")\n",
        "\n",
        "#             # Now download\n",
        "#             ydl.download([url])\n",
        "\n",
        "#             # Extract comprehensive metadata\n",
        "#             metadata = extract_comprehensive_metadata(info)\n",
        "\n",
        "#             print(\"✅ Video downloaded successfully!\")\n",
        "#             return metadata, info\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Download failed: {e}\")\n",
        "#         return None, None\n",
        "\n",
        "# def extract_comprehensive_metadata(info):\n",
        "#     \"\"\"\n",
        "#     Extract comprehensive metadata from yt-dlp info\n",
        "#     \"\"\"\n",
        "#     metadata = {\n",
        "#         # Basic Info\n",
        "#         \"title\": info.get('title', 'Unknown'),\n",
        "#         \"uploader\": info.get('uploader', 'Unknown'),\n",
        "#         \"uploader_id\": info.get('uploader_id', 'Unknown'),\n",
        "#         \"channel\": info.get('channel', 'Unknown'),\n",
        "#         \"channel_id\": info.get('channel_id', 'Unknown'),\n",
        "\n",
        "#         # Video Details\n",
        "#         \"duration\": info.get('duration', 0),\n",
        "#         \"view_count\": info.get('view_count', 0),\n",
        "#         \"like_count\": info.get('like_count', 0),\n",
        "#         \"upload_date\": info.get('upload_date', 'Unknown'),\n",
        "#         \"description\": info.get('description', 'No description')[:500],  # First 500 chars\n",
        "\n",
        "#         # Technical Details\n",
        "#         \"width\": info.get('width', 0),\n",
        "#         \"height\": info.get('height', 0),\n",
        "#         \"fps\": info.get('fps', 0),\n",
        "#         \"format\": info.get('format', 'Unknown'),\n",
        "#         \"filesize\": info.get('filesize', 0),\n",
        "\n",
        "#         # Additional\n",
        "#         \"tags\": info.get('tags', [])[:10],  # First 10 tags\n",
        "#         \"categories\": info.get('categories', []),\n",
        "#         \"thumbnail\": info.get('thumbnail', ''),\n",
        "#         \"webpage_url\": info.get('webpage_url', ''),\n",
        "#     }\n",
        "\n",
        "#     return metadata"
      ],
      "metadata": {
        "id": "HwW85nRxK5xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from moviepy.editor import VideoFileClip\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# def get_video_file_path(output_path):\n",
        "#     \"\"\"Find the downloaded video file\"\"\"\n",
        "#     video_extensions = ['.mp4', '.mkv', '.webm', '.avi']\n",
        "\n",
        "#     for ext in video_extensions:\n",
        "#         video_path = os.path.join(output_path, f'input_vid{ext}')\n",
        "#         if os.path.exists(video_path):\n",
        "#             return video_path\n",
        "\n",
        "#     # If not found with expected name, look for any video file\n",
        "#     for file in os.listdir(output_path):\n",
        "#         if any(file.endswith(ext) for ext in video_extensions):\n",
        "#             return os.path.join(output_path, file)\n",
        "\n",
        "#     return None\n",
        "\n",
        "# def video_to_images_enhanced(video_path, output_folder, fps=0.5, max_frames=50):\n",
        "#     \"\"\"\n",
        "#     Extract frames from video with enhanced options\n",
        "#     \"\"\"\n",
        "#     os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "#     try:\n",
        "#         clip = VideoFileClip(video_path)\n",
        "#         duration = clip.duration\n",
        "\n",
        "#         print(f\"🎬 Video duration: {duration:.2f} seconds\")\n",
        "#         print(f\"📸 Extracting frames at {fps} FPS...\")\n",
        "\n",
        "#         # Calculate frame interval\n",
        "#         interval = 1.0 / fps\n",
        "#         frame_count = 0\n",
        "\n",
        "#         for t in np.arange(0, min(duration, max_frames * interval), interval):\n",
        "#             if frame_count >= max_frames:\n",
        "#                 break\n",
        "\n",
        "#             frame_path = os.path.join(output_folder, f\"frame_{frame_count:04d}.png\")\n",
        "#             clip.save_frame(frame_path, t)\n",
        "#             frame_count += 1\n",
        "\n",
        "#         clip.close()\n",
        "#         print(f\"✅ Extracted {frame_count} frames\")\n",
        "#         return frame_count\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Frame extraction failed: {e}\")\n",
        "#         return 0\n",
        "\n",
        "# def video_to_audio_enhanced(video_path, output_audio_path):\n",
        "#     \"\"\"\n",
        "#     Extract audio with enhanced options\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         clip = VideoFileClip(video_path)\n",
        "#         audio = clip.audio\n",
        "\n",
        "#         # Extract audio\n",
        "#         audio.write_audiofile(\n",
        "#             output_audio_path,\n",
        "#             codec='pcm_s16le',  # WAV format\n",
        "#             verbose=False,\n",
        "#             logger=None\n",
        "#         )\n",
        "\n",
        "#         clip.close()\n",
        "#         print(f\"🎵 Audio extracted to: {output_audio_path}\")\n",
        "#         return True\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ Audio extraction failed: {e}\")\n",
        "#         return False"
      ],
      "metadata": {
        "id": "bSCNfochK57M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def process_video_complete(video_url, base_output_path=\"/content\"):\n",
        "#     \"\"\"\n",
        "#     Complete video processing pipeline\n",
        "#     \"\"\"\n",
        "#     # Setup paths\n",
        "#     video_output_path = os.path.join(base_output_path, \"video_data\")\n",
        "#     mixed_output_path = os.path.join(base_output_path, \"mixed_data\")\n",
        "#     frames_output_path = os.path.join(mixed_output_path, \"frames\")\n",
        "#     audio_output_path = os.path.join(mixed_output_path, \"output_audio.wav\")\n",
        "\n",
        "#     # Create directories\n",
        "#     os.makedirs(video_output_path, exist_ok=True)\n",
        "#     os.makedirs(mixed_output_path, exist_ok=True)\n",
        "#     os.makedirs(frames_output_path, exist_ok=True)\n",
        "\n",
        "#     print(\"🚀 Starting complete video processing pipeline...\")\n",
        "\n",
        "#     # Step 1: Download video\n",
        "#     print(\"\\n📥 Step 1: Downloading video...\")\n",
        "#     metadata, full_info = download_video_with_ytdlp(video_url, video_output_path)\n",
        "\n",
        "#     if not metadata:\n",
        "#         print(\"❌ Failed to download video\")\n",
        "#         return None\n",
        "\n",
        "#     # Step 2: Find video file\n",
        "#     video_path = get_video_file_path(video_output_path)\n",
        "#     if not video_path:\n",
        "#         print(\"❌ Could not find downloaded video file\")\n",
        "#         return None\n",
        "\n",
        "#     print(f\"📹 Video file: {video_path}\")\n",
        "\n",
        "#     # Step 3: Extract frames\n",
        "#     print(\"\\n🖼️ Step 2: Extracting frames...\")\n",
        "#     frame_count = video_to_images_enhanced(video_path, frames_output_path, fps=0.3, max_frames=30)\n",
        "\n",
        "#     # Step 4: Extract audio\n",
        "#     print(\"\\n🎵 Step 3: Extracting audio...\")\n",
        "#     audio_success = video_to_audio_enhanced(video_path, audio_output_path)\n",
        "\n",
        "#     # Step 5: Audio to text (if needed)\n",
        "#     text_content = \"\"\n",
        "#     if audio_success:\n",
        "#         print(\"\\n📝 Step 4: Converting audio to text...\")\n",
        "#         try:\n",
        "#             text_content = audio_to_text(audio_output_path)\n",
        "#             print(f\"📄 Extracted text length: {len(text_content)} characters\")\n",
        "#         except Exception as e:\n",
        "#             print(f\"⚠️ Audio to text conversion failed: {e}\")\n",
        "\n",
        "#     # Compile results\n",
        "#     results = {\n",
        "#         \"metadata\": metadata,\n",
        "#         \"video_path\": video_path,\n",
        "#         \"frames_path\": frames_output_path,\n",
        "#         \"frame_count\": frame_count,\n",
        "#         \"audio_path\": audio_output_path if audio_success else None,\n",
        "#         \"text_content\": text_content,\n",
        "#         \"full_info\": full_info\n",
        "#     }\n",
        "\n",
        "#     print(\"\\n✅ Processing complete!\")\n",
        "#     print(f\"📊 Summary:\")\n",
        "#     print(f\"   - Video: {metadata['title']}\")\n",
        "#     print(f\"   - Duration: {metadata['duration']} seconds\")\n",
        "#     print(f\"   - Frames extracted: {frame_count}\")\n",
        "#     print(f\"   - Audio extracted: {'Yes' if audio_success else 'No'}\")\n",
        "#     print(f\"   - Text extracted: {'Yes' if text_content else 'No'}\")\n",
        "\n",
        "#     return results"
      ],
      "metadata": {
        "id": "-r3909DJLSj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Your video URL\n",
        "# video_url = \"https://youtu.be/yIYKR4sgzI8?si=gXmg-aTIhioj1pOs\"\n",
        "\n",
        "# # Process the video\n",
        "# results = process_video_complete(video_url)\n",
        "\n",
        "# if results:\n",
        "#     print(\"\\n📋 Detailed Results:\")\n",
        "#     pprint(results[\"metadata\"])\n",
        "\n",
        "#     # Save metadata to file\n",
        "#     import json\n",
        "#     with open(\"/content/mixed_data/video_metadata.json\", \"w\") as f:\n",
        "#         json.dump(results[\"metadata\"], f, indent=2)\n",
        "\n",
        "#     print(\"\\n💾 Metadata saved to video_metadata.json\")\n",
        "# else:\n",
        "#     print(\"❌ Video processing failed\")"
      ],
      "metadata": {
        "id": "ZSZjc2BDLYDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xu_hUn4RMsM1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}